{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "RFjrV07Spmm2"
            },
            "source": [
                "# Create YOLO dataset structure for training process\n",
                "\n",
                "---\n",
                "\n",
                "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](notebook_link)\n",
                "\n",
                "This cookbook utilizes [sv.DetectionDataset()](https://supervision.roboflow.com/latest/datasets/core/#supervision.dataset.core.DetectionDataset) methods and other Supervision utilities to effortlessly create a YOLO dataset structure for training process"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "aFQHoaDLp8R3"
            },
            "source": [
                "Click the `Open in Colab` button to run the cookbook on Google Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q tqdm supervision==0.22.0 ultralytics"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Import required libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import supervision as sv\n",
                "from supervision.assets import download_assets, VideoAssets\n",
                "from ultralytics import YOLO"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### YOLO model folders structure for training process\n",
                "\n",
                "\n",
                "train\\\n",
                "├── images\\\n",
                "├── labels\\\n",
                "valid\\\n",
                "├── images\\\n",
                "├── labels\\\n",
                "test\\\n",
                "├── images\\\n",
                "├── labels\\\n",
                "data.yaml\n",
                "\n",
                "\n",
                "<br>YOLO datasets splits in three folders `train`, `valid`, `test` and each folder must have two subfolders `images`, `labels` containing the images and their corresponding labels. Each image-label pair must have the same file name with different extension (e.g. image_001.jpg -> image_001.txt)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Download video sample to create folders with images and labels\n",
                "\n",
                "#### ⚠️ If you have already a dataset with `images` and `labels` folders containing the images and corresponding labels, you can directly skip the following sections and go to [3. Split images and create dataset](#3-split-images-and-create-dataset).\n",
                "\n",
                "Let's create a dataset using Supervision Assets. First, we download the video asset using [\"download_assets()\"](https://supervision.roboflow.com/latest/assets/#supervision.assets.downloader.download_assets) and [\"VideoAssets\"](https://supervision.roboflow.com/latest/assets/#supervision.assets.list.VideoAssets) and we create `images` and `labels` folders to dump video frames and extracted labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "HOME = os.getcwd()\n",
                "SOURCE_VIDEO_PATH = download_assets(VideoAssets.PEOPLE_WALKING)\n",
                "DATASET = f\"{HOME}/dataset\"\n",
                "!mkdir -p {DATASET} {DATASET}/images {DATASET}/labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As a result of executing the above `download_assets(VideoAssets.PEOPLE_WALKING)` , you will download a video file and save it at the `SOURCE_VIDEO_PATH`.\n",
                "\n",
                "<video controls width=\"1280\">\n",
                "  <source src=\"https://media.roboflow.com/supervision/video-examples/people-walking.mp4\" type=\"video/mp4\">\n",
                "</video>\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then using [`sv.ImageSink()`](https://supervision.roboflow.com/develop/utils/image/#supervision.utils.image.ImageSink) and [`sv.get_video_frames_generator()`](https://supervision.roboflow.com/develop/utils/video/#supervision.utils.video.get_video_frames_generator) we export all frames from the processed video."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with sv.ImageSink(target_dir_path=f\"{DATASET}/images\", image_name_pattern=\"image_{:03d}.jpg\") as sink:\n",
                "    for image in sv.get_video_frames_generator(SOURCE_VIDEO_PATH):\n",
                "        sink.save_image(image=image)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now our images are exported in `images` folder, next step is to export the labels for each frame.\\\n",
                "First we load the YOLO model that we want and then we extract the results by predicting on our video."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIDENCE_THRESHOLD = 0.3\n",
                "INFERENCE_MODEL = \"yolov8n.pt\"\n",
                "\n",
                "model = YOLO(\"yolov8n.pt\")\n",
                "results = model(source=\"people-walking.mp4\", conf=CONFIDENCE_THRESHOLD)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Create `sv.DetectionDataset()` object to define labels, images, and annotations of the dataset\n",
                "1) First we extract the labels dictionary from YOLO model, and convert them to an order list that contains only the label names.<br/>\n",
                "\n",
                "2) Using the [`sv.list_files_with_extensions()`](https://supervision.roboflow.com/develop/utils/file/#supervision.utils.file.list_files_with_extensions) and specifying the directory and files extensions, we retrieve a list of the images paths <br/>\n",
                "\n",
                "3) We create a dictionary where keys are the image paths, and the corresponding values are the detections for each frame transformed using [`sv.Detections.from_ultralytics()`](https://supervision.roboflow.com/develop/detection/core/#supervision.detection.core.Detections.from_ultralytics)<br/>\n",
                "\n",
                "4) We create an [`sv.DetectionDataset()`](https://supervision.roboflow.com/develop/datasets/core/#supervision.dataset.core.DetectionDataset) object by passing the `classes`, `images`, `annotations` arguments that have already been created <br/>\n",
                "\n",
                "5) Finally, we utilize [`as_yolo()`](https://supervision.roboflow.com/develop/datasets/core/#supervision.dataset.core.DetectionDataset.as_yolo) method to export the labels to the selected path, and also create a `data.yaml` file needed for the training process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "classes_dict = model.model.names\n",
                "classes = [class_name for class_name in classes_dict.values()]\n",
                "image_paths = sv.list_files_with_extensions(directory=f\"{DATASET}/images\", extensions=['jpg'])\n",
                "\n",
                "annotations_dict = {}\n",
                "\n",
                "for image_path, detections in zip(image_paths, results):\n",
                "    detections = sv.Detections.from_ultralytics(detections)\n",
                "    annotations_dict[image_path] = detections\n",
                "\n",
                "ds = sv.DetectionDataset(\n",
                "    classes=classes,\n",
                "    images=image_paths,\n",
                "    annotations=annotations_dict\n",
                ")\n",
                "\n",
                "ds.as_yolo(\n",
                "    annotations_directory_path=f\"{DATASET}/labels\",\n",
                "    data_yaml_path=f\"{DATASET}/data.yaml\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Split images and create dataset\n",
                "\n",
                "Now we have an `images` folder which contains all the images of the dataset, and an `labels` folder which contains the corresponding labels of each image <br/>\n",
                "\n",
                "Our goal is to automatically split the images and place them in `images`, `labels` subfolders based on the specified split ratios <br/>\n",
                "\n",
                "Using [`sv.DetectionDataset.from_yolo()`](https://supervision.roboflow.com/develop/datasets/core/#supervision.dataset.core.DetectionDataset.from_yolo) we load our dataset by specifying the paths for `images`, `labels`, and `data.yaml`<br/>\n",
                "\n",
                "We specify the `TRAIN_RATIO` and `VALID_RATIO` and then the test ratio is calculated automatically. (⚠️ Note that train and valid ratios shouldn't surpass `1.0` in total, and each value should be higher that 0 and lower than 1.0)<br/>\n",
                "\n",
                "In order to split the dataset in individual datasets, we use [`sv.DetectionDataset.split()`](https://supervision.roboflow.com/develop/datasets/core/#supervision.dataset.core.DetectionDataset.split) method"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = sv.DetectionDataset.from_yolo(\n",
                "    images_directory_path=f\"{DATASET}/images\",\n",
                "    annotations_directory_path=f\"{DATASET}/labels\",\n",
                "    data_yaml_path=f\"{DATASET}/data.yaml\"\n",
                ")\n",
                "\n",
                "TRAIN_RATIO = 0.7\n",
                "VALID_RATIO = 0.2\n",
                "\n",
                "def check_ratios(train_ratio, valid_ratio):\n",
                "    condition1 = (0 < train_ratio < 1.0) and (0 < valid_ratio < 1.0)\n",
                "    condition2 = (train_ratio + valid_ratio) <= 1.0\n",
                "\n",
                "    if not (condition1 and condition2):\n",
                "        raise ValueError(\"TRAIN_RATIO and VALID_RATIO must be between 0 and 1, and their sum must not exceed 1.0\")\n",
                "\n",
                "check_ratios(TRAIN_RATIO, VALID_RATIO)\n",
                "\n",
                "train_ds, valid_ds = dataset.split(split_ratio=TRAIN_RATIO)\n",
                "\n",
                "_VALID_RATIO = VALID_RATIO/(1-TRAIN_RATIO)\n",
                "valid_ds, test_ds = valid_ds.split(split_ratio=_VALID_RATIO)\n",
                "\n",
                "_datasets = (train_ds, valid_ds, test_ds)\n",
                "_folders = [\"train\", \"valid\", \"test\"]\n",
                "\n",
                "for dataset, folder in zip(_datasets, _folders):\n",
                "    dataset.as_yolo(\n",
                "        images_directory_path=os.path.join(f\"{DATASET}\", folder, \"images\"),\n",
                "        annotations_directory_path=os.path.join(f\"{DATASET}\", folder, \"labels\"),\n",
                "        data_yaml_path=f\"{DATASET}/data.yaml\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Model training\n",
                "\n",
                "Now `train`, `valid`, `test` folders and `data.yaml` are ready for training process!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.train(data = f\"{DATASET}/data.yaml\", epochs = 10, imgsz = 640, batch = 32, lr0 = 0.001)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
